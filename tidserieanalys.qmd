---
title: "Marking guide assignment GLM"
author: "Jacob rak, William Lindquist. Aram Vardanian"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
  html_document:
    toc: true
    toc_float: true
editor_options:
  markdown:
    wrap: 72
---

```{r, warning=FALSE, message=FALSE}
library(mvtnorm)
library(tseries)
library(vars)
library(forecast)
```

# Step 1

Datasetet kommer från
[https://www.kaggle.com/datasets/vijayvvenkitesh/microsoft-stock-time-series-analysis](#0).
Datasetet är en tidserieanalys av Microsoft aktiken MSTF som är listad
på den amerikanska markanden. Uppgifterna hämtades från Google Sheets
med hjälp av "GOOGLEFINANCE".

```{r}
dataframe = read.csv("Microsoft_Stock.csv")

```

## Varibler

Datasetet har över 1511 observationer med 6 olika varibler.

-   Date(från 04/01/2015 till 04/01/2021)

-   Open(Pris vid öppning)

-   high(högst värdet för den dagen)

-   Low(lägsta priset)

-   Close(stängnings priset)

-   Volume(volymen av sålda aktiker)

## Periodictet

Periodiciteten av dataframen är dagligen.

## Val av varibler

För en robust och nyancerad analys kommer det framförallt används av
Open, high och low som hjälpvariblen och Close som huvudvarible.
Motiveringen följer, det finns en naturlig koppling mellan dessa för att
kunna förutspå aktien closing price från ett mänskligt perpektiv.

## Grafer

```{r}
# Matrix
dataframe <- as.matrix(dataframe[, c("Open", "High", "Low", "Close", "Volume")])

microsoft_ts <- ts(dataframe, 
               start = c(2015, 4),  
               frequency = 365)

# Subset data
microsoft_ts_trimmed <- ts(
  microsoft_ts[1:(1511 - 30), ],       
  start = start(microsoft_ts),         
  frequency = frequency(microsoft_ts)  
)

```

```{r}
plot(microsoft_ts_trimmed, main="")

```

```{r}
plot(microsoft_ts_trimmed[, "Close"], 
     main = "Closing price over time",
     xlab = "date",
     ylab = "Closing price")
```

# Step 2

## a) Expontial smoothing

Exponetial smoothing använder man holtwinters() med $Gamma = False$ och
$beta = False$ kommer ge en enkel expoential smoothing!

```{r}
close_ts <- microsoft_ts_trimmed[, "Close"]

exp_smoother <- HoltWinters(close_ts,alpha =0.1, beta = FALSE, gamma = FALSE)

plot(exp_smoother, main = "Exponential Smoothing - Closing Price", ylab = "Closing Price", xlab = "Date")

legend("topleft", legend = c("Original", "Exponential Values"), col = c("black", "red"), lty = 1)


```

## b) Rolling_forecast

Skapa en funktion som hittar rolling_forecast

```{r}
rolling_forecast <- function(
    data,
    first_pred = 2019 + 23/365,
    last_pred = 2019 + 56/365,
    steps_ahead = 1
) {
    end <- first_pred - 1/365
    preds <- list()
    i <- 1
  
    while (end <= (last_pred - 0.01)) {
        train <- window(data, end = end)
        model <- HoltWinters(train)
        preds[[i]] <- predict(model, n.ahead = steps_ahead)
        end <- end + 1/365
        i <- i + 1
    }
  
    all_preds <- ts(
        unlist(preds),
        start = first_pred,
        frequency = frequency(data)
    )
  
    return(all_preds)
}
```

Predict på datan

```{r, message=FALSE, warning=FALSE}
microsoft_ts_rolling <- microsoft_ts[, 4]
forecast <- rolling_forecast(
    data=microsoft_ts_rolling,
    steps_ahead = 1
)
forecast_hS <- rolling_forecast(
    data = microsoft_ts_rolling,
    steps_ahead = 4
)
```

Plotting forecast

```{r}
plot(forecast)
plot(forecast_hS)
```

Räknar ut båda RMSE och MAD

```{r}
microsoft_ts_trimmed_last_30 <- ts(
  microsoft_ts[1481:1511, ],       
  start = end(microsoft_ts_trimmed),         
  frequency = frequency(microsoft_ts)  
)


calc_metrics <- function(actual, predicted) {
    rmse <- sqrt(mean((actual - predicted)^2, na.rm = TRUE))
    mad <- mean(abs(actual - predicted), na.rm = TRUE)
    c(RMSE = rmse, MAD = mad)
}


metrics0 <- calc_metrics(actual = microsoft_ts_trimmed_last_30[,4], predicted = forecast)
metrics0
metrics1 <- calc_metrics(actual = microsoft_ts_trimmed_last_30[,4], predicted = forecast_hS)
metrics1
```

## c) Plot

```{r}
alpha <- 0.05
z <- qnorm(1 - alpha / 2)

# plot
plot(microsoft_ts_trimmed_last_30[, 4], col = "black", lwd = 2, main = "h = 1",
     ylab = "price")
lines(forecast, col = "blue", lwd = 2)
polygon(c(time(forecast), rev(time(forecast))),
        c(forecast - z * sd(forecast), rev(forecast + z * sd(forecast))),
        col = rgb(0, 0, 1, 0.2), border = NA)

plot(microsoft_ts_trimmed_last_30[, 4], col = "black", lwd = 2, main = "h = S",
     ylab = "price")
lines(forecast_hS, col = "blue", lwd = 2)
polygon(c(time(forecast_hS), rev(time(forecast_hS))),
        c(forecast_hS - z * sd(forecast_hS), 
        rev(forecast_hS + z * sd(forecast_hS))),
        col = rgb(1, 0, 0, 0.2), border = NA)


```

## d) Random walk

```{r}
set.seed(99)

N <- length(microsoft_ts_trimmed_last_30[, 4])
x0 <- microsoft_ts_trimmed_last_30[, 4][1]
mu <- mean(diff(microsoft_ts_trimmed_last_30[, 4]))
variance <- var(diff(microsoft_ts_trimmed_last_30[, 4]))

RW <- function(N, x0, mu, variance) {
  z <- cumsum(rnorm(n = N, mean = 0, sd = sqrt(variance)))
  t <- 1:N
  x <- x0 + t * mu + z
  return(x)
}

random_walk <- RW(N = N, x0 = x0, mu = mu, variance = variance)

random_walk_ts <- ts(random_walk, start = start(microsoft_ts_trimmed_last_30),
                     frequency = frequency(microsoft_ts_trimmed_last_30))

plot(random_walk_ts, type = "l", col = "blue", lwd = 2, 
     main = "Random Walk", 
     xlab = "Time", 
     ylab = "Price")

lines(microsoft_ts_trimmed_last_30[, 4], 
      col = "red", 
      lwd = 2, 
      lty = 2)

legend("topright", 
       legend = c("Random Walk", "Original Data"), 
       col = c("blue", "red"),
        lty = c(1, 2), 
       lwd = c(2, 2))

```

## Lets simulate a few random walks

```{r}
set.seed(99)
score <- c(RMSE = 0, MAD = 0)
best_model = c(RMSE = 0, MAD = 0)
best_rmse <- Inf

for (i in 1:1000){
  random_walk <- RW(N = N, x0 = x0, mu = mu, variance = variance)

  random_walk_ts <- ts(random_walk, start = start(microsoft_ts_trimmed_last_30),
                       frequency = frequency(microsoft_ts_trimmed_last_30))
  
  result = calc_metrics(actual = microsoft_ts_trimmed_last_30[,4], 
                        predicted = random_walk_ts)
  score = score + result
  if (result["RMSE"] < best_rmse){
    best_rmse = result["RMSE"]
    best_model = result
  }
 
}
score/1000
best_model
```

## e) Tolka resultatet!

Efter 1000 random Simuleringar av random walk modellen fick en model
värden:

```         
    RMSE      MAD  4.109651 3.642226
```

Expontiella smoothing fick följande värden med 1 stepahead respktiv 4
steps ahead:

```         
    RMSE      MAD  4.040513 3.246373 h1
    
    RMSE      MAD  7.935299 5.960994 h4
```

1 stepahead modellen verkar i detta example vara överlägsen över 4
stepahead modellen, eftersom data verkar ha hög volatilitet och
anpassningen av h4 modellen verkar långsammare och mindre anpassad till
dramtiska förändringar. Detta resultat stämmer överens med aktie data
som ofta påverkas likt en random model med ar(1).

I snitt när man undersöker random walk modellen tenderar den att vara en
ganska kraftig del sämre. Detta antyder på att den expoentiala modellen
är överlag bättre för att analysera de sista 30 observationerna. Dock
krävs mer forskning om man istället hade ändrat sista tidperioden till
längre fram eller bak kan resultaten skillnad sig. Utöver det borde man
kanske testa en randomwalk med drift för ännu bättre resultat.

```         
    RMSE      MAD  15.25995 13.15743 
```

# Step 3 Stionarity

```{r}
microsoft_stationarity =microsoft_ts_trimmed
adf_main <- adf.test(microsoft_stationarity[, 4], alternative = "stationary")
adf_1 <- adf.test(microsoft_stationarity[, 1], alternative = "stationary")
adf_2 <- adf.test(microsoft_stationarity[, 2], alternative = "stationary")
adf_3 <- adf.test(microsoft_stationarity[, 3], alternative = "stationary")
print(adf_main)
print(adf_1)
print(adf_2)
print(adf_3)
```

## b) transform 

```{r}
microsoft_stationarity = log(log(microsoft_ts_trimmed))

adf_main <- adf.test(microsoft_stationarity[, 4], alternative = "stationary")
adf_1 <- adf.test(microsoft_stationarity[, 1], alternative = "stationary")
adf_2 <- adf.test(microsoft_stationarity[, 2], alternative = "stationary")
adf_3 <- adf.test(microsoft_stationarity[, 3], alternative = "stationary")
print(adf_main)
print(adf_1)
print(adf_2)
print(adf_3)
```

## c)

```{r}
diff_main <- diff(microsoft_ts[, 4])
diff_supporting <- diff(microsoft_ts[, 1:3])
plot(diff_main)
plot(diff_supporting)

acf(diff_main, main = "ACF - Main Series")
pacf(diff_main, main = "PACF - Main Series")

acf(diff_supporting, main = "ACF - Supporting Series")
pacf(diff_supporting, main = "PACF - Supporting Series")
```

# Step 4 ARMA

```{r}
adf_test <- adf.test(microsoft_ts_trimmed[, 4])
print(adf_test)

close_ts_diff <- diff(microsoft_ts_trimmed[, 4])
adf_test_diff <- adf.test(close_ts_diff)
print(adf_test_diff)

close_ts_diff2 <- diff(close_ts_diff)
adf_test_diff2 <- adf.test(close_ts_diff2)
print(adf_test_diff2)
```

ADF-test (Augmentes Dickey-Fuller test), för att avgöra om tidsserien är
stationär eller inte. En stationär tidsseriedata innebär att de
statistiska egenskaperna som medelvärde, varians och autokorrelation
inte förändras över tid. Då datan är större än 0,05 innebär det att den
inte är stationär. Vi differentierar tidsserien 2 gånger för att göra
den stationär. Differentiering innebär att vi beräknar förändringen från
en period till nästa. (yt - (yt-1)).

```{r}
par(mfrow = c(1, 2))
acf(close_ts_diff2, main = "ACF")
pacf(close_ts_diff2, main = "PACF")
```

Vi använder ACF (autokorrelationsfunktion) och PACF (partiell
autokorrelationsfunktion för att identifiera ordningen av AR (p) och MA
(q).

```{r}
arma_model <- auto.arima(microsoft_ts_trimmed[, 4], seasonal = FALSE)
summary(arma_model)
```

```{r}
#Prognos med modellen
fitted_values <- fitted(arma_model)

#Plottar originaldata och anpassade värden
plot(microsoft_ts_trimmed[, 4], main = "Originaldata och ARMA Fitted Värden", ylab = "Close Pris", col = "blue")
lines(fitted_values, col = "red", lwd = 1)
legend("topleft", legend = c("Originaldata", "Fitted Värden"), col = c("blue", "red"), lwd = 2)
```

## b) Residuals

```{r}
#Kontrollerar residualerna
checkresiduals(arma_model)
```

Med ett p-värde på 0,9706 innebär det att vi måste förkasta
nollhypotesen, alltså har residualerna ingen signifikant
autokorrelation, då p-värdet är \> 0,05.

Residualplotten (övre bild) visar att främst ligger runt 0 vilket är ett
bra tecken. Dock med en extrem outlier i slutet av serien, vilket verkar
vara en avvikelse, om man inte skulle fortsätta tidsserien.

ACF-plotten visar att majoriteten av residualerna ligger inom de
blå-streckade gränserna, vilket tyder på att det inte finns någon
kvarvarande autokorrelation, vilket vårt p-värde även sa. Histogrammet
verkar tyda på en normalfördelning, vilket är önskvärt.

## c) Rolling_forecast_arma

```{r}
rolling_forecast_arma <- function(data,
    first_pred = 2019 + 23/365,
    last_pred = 2019 + 56/365,
    steps_ahead = 1) 
  {
    end <- first_pred - 1/365 
    preds <- list()
    i <- 1
  
    while (end < (last_pred - 0.01)) {
        train <- window(data, end = end)
        model <- auto.arima(train, seasonal = FALSE)
        forecast_result <- forecast(model, h = steps_ahead)
        preds[[i]] <- forecast_result$mean[steps_ahead]
        end <- end + 1/365
        i <- i + 1
    }
    all_preds <- ts(
        unlist(preds),
        start = first_pred,
        frequency = frequency(data))
  
    return(all_preds)}
```

```{r}
microsoft_ts_rolling = microsoft_ts[, 4]
forecast_arma <- rolling_forecast_arma(data=microsoft_ts_rolling,
                             steps_ahead = 1)

forecast_hS_arma <- rolling_forecast_arma(
    data=microsoft_ts_rolling,
    steps_ahead = 4)
```

## d) Plot

```{r}
alpha <- 0.05
z <- qnorm(1 - alpha / 2)

# plot
plot(microsoft_ts_trimmed_last_30[, 4], col = "black", lwd = 2, main = "h = 1",
     ylab = "price")
lines(forecast_arma, col = "blue", lwd = 2)
polygon(c(time(forecast_arma), rev(time(forecast_arma))),
        c(forecast_arma - z * sd(forecast_arma), rev(forecast_arma + z * sd(forecast_arma))),
        col = rgb(0, 0, 1, 0.2), border = NA)

plot(microsoft_ts_trimmed_last_30[, 4], col = "black", lwd = 2, main = "h = S",
     ylab = "price")
lines(forecast_hS_arma, col = "blue", lwd = 2)
polygon(c(time(forecast_hS_arma), rev(time(forecast_hS_arma))),
        c(forecast_hS_arma - z * sd(forecast_hS_arma), 
        rev(forecast_hS_arma + z * sd(forecast_hS_arma))),
        col = rgb(1, 0, 0, 0.2), border = NA)
```

## e) RMSE

```{r}
metrics2 = calc_metrics(microsoft_ts_trimmed_last_30[, 4], forecast_arma)
metrics3 = calc_metrics(microsoft_ts_trimmed_last_30[, 4], forecast_hS_arma)
metrics2
metrics3

score/1000
best_model
```

Från tidigare uppgifter har det etablerads en baseline random walk
modell i detta fall ser vi tydligt att båda valen av Arma model får
bättre resultat en den bästa random walk modellen ur 1000 simulationer
då kan vi säkersälla att ARMA är bättre modelval.

# Step 5 Var

a\)

```{r}
VAR_micro <- VAR(microsoft_ts_trimmed[, 1:4])

residuals_close <- residuals(VAR_micro)

acf((residuals_close)[, c("Close", "High")])
acf((residuals_close)[, c("Close", "Open")])
acf((residuals_close)[, c("Close", "Low")])
```

Använder normality.test för att testa objektens normalitet. Det hög p
värdet antyder tydligt att det väldigt signifikanta villket beskriver
att vår data inte är normalfördelad

```{r}
normality_test <- normality.test(VAR_micro)
print(normality_test)
```

## C) impulse response

```{r}
irf_VAR <- irf(VAR_micro,impulse = "Close", n.ahead = 20)

plot(irf_VAR)
```

Resultatet påperkar att de första lagen för open, high och low skuter
upp över den röda 95% CI och sedan till slut jämnar ut sig vid runt 0.25
ish

## d) rolling forecast var

```{r}
rolling_forecast_var <- function(
    data,
    first_pred = 2019 + 23/365,
    last_pred = 2019 + 56/365,
    steps_ahead = 1
) {
    end <- first_pred - 1/365
    preds <- list()
    i <- 1
  
    while (end <= (last_pred - 0.01)) {
        train <- window(data, end = end)
        model <- VAR(train, lag.max = 12)
        forecast_result <- predict(model, n.ahead = steps_ahead)
        forecasted <- forecast_result$fcst[[ncol(data)]][steps_ahead, "fcst"]
        preds[[i]] <- forecasted
        end <- end + 1/365
        i <- i + 1
    }
  
    all_preds <- ts(
        unlist(preds),
        start = first_pred,
        frequency = frequency(data)
    )
  
    return(all_preds)
}
```

```{r, warning=False}
microsoft_ts_rolling <- microsoft_ts[, 1:4]
forecast_var <- rolling_forecast_var(
    data=microsoft_ts_rolling,
    steps_ahead = 1
)
forecast_hS_var <- rolling_forecast_var(
    data = microsoft_ts_rolling,
    steps_ahead = 4
)

```

```{r}
plot(forecast_var)
plot(forecast_hS_var)
```

## e) Plot

```{r}
alpha <- 0.05
z <- qnorm(1 - alpha / 2)

# plot
plot(microsoft_ts_trimmed_last_30[, 4], col = "black", lwd = 2, main = "h = 1",
     ylab = "price")
lines(forecast_var, col = "blue", lwd = 2)
polygon(c(time(forecast_var), rev(time(forecast_var))),
        c(forecast_var - z * sd(forecast_var), rev(forecast_var + z * sd(forecast_var))),
        col = rgb(0, 0, 1, 0.2), border = NA)

plot(microsoft_ts_trimmed_last_30[, 4], col = "black", lwd = 2, main = "h = S",
     ylab = "price")
lines(forecast_hS_var, col = "blue", lwd = 2)
polygon(c(time(forecast_hS_var), rev(time(forecast_hS_var))),
        c(forecast_hS_var - z * sd(forecast_hS_var), 
        rev(forecast_hS_var + z * sd(forecast_hS_var))),
        col = rgb(1, 0, 0, 0.2), border = NA)

```

## f) g) Random walk och RMSE

```{r}
metrics4 = calc_metrics(microsoft_ts_trimmed_last_30[, 4], forecast_var)
metrics5 = calc_metrics(microsoft_ts_trimmed_last_30[, 4], forecast_hS_var)
metrics4
metrics5


score/1000
best_model
```

Utifrån våra tidigare 1000 simlueringar kan vi kostatera att i
genomsnitt preseterar en random walk sämre för vårt window i detta fall.
Det antyder på att VAR modellen är bättre anpassad till vårt dataset

## h) Jämföra modeller

```{r}
print("exp")
metrics0
metrics1
print("arma")
metrics2
metrics3
print("Var")
metrics4
metrics5
```

När vi jämför tidigare har vi sett att en random walk modell fungerar
förvänads värt dåligt i jämförlse till de andra modeller. Finaniciell
data brukar oftast likna en "random walk" men i vårt fall gäller detta
påstende inte riktigt men mönstrerna liknar absolut en random walk.

Alla modeller med step.ahead = 1 presterad alltid bättre det inte
konstigt då i vår dataset har vi ingen seasonality. VAR var absolut bäst
med Arma lite bakom och sen expontial smoothing
